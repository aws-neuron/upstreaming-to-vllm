# SPDX-License-Identifier: Apache-2.0
"""
Neuron KV Cache Connector for Disaggregated Inference

"""

import json
import os
import threading
import time
from typing import List, Tuple, Union

import torch
import zmq

from vllm.distributed.kv_transfer.kv_connector.base import KVConnectorBase
from vllm.distributed.kv_transfer.neuron.neuron_buffer import NeuronBuffer
from vllm.logger import init_logger
from vllm.sequence import IntermediateTensors
from vllm.worker.model_runner import ModelInputForGPUWithSamplingMetadata

logger = init_logger(__name__)


def get_local_ip():
    import socket
    try:
        # Create a socket connection to an external server
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # Doesn't actually connect to 8.8.8.8
        #   but tells us which interface to use
        s.connect(("8.8.8.8", 80))
        local_ip = s.getsockname()[0]
        s.close()
        return local_ip
    except Exception:
        return "127.0.0.1"


def create_lease_with_retry(etcd_client, ttl=60, max_retries=3):
    for attempt in range(max_retries):
        try:
            lease = etcd_client.lease(ttl=ttl)
            return lease
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            time.sleep(1)
    return None


def parse_request_id(request_id):
    """
    request_id should be in the format of

    '<uuid>_<remote_ip>:<remote_api_server_port>'

    uuid: unique request id generated by proxy server
    remote_ip: remote ip for KV cache transfer
    remote_api_server_port: port for API server


    TODO: could we improve this implicit rule?
    We will API server port + 1 from prefill worker as
        port for zmq server.

    TODO: extend it to support multi-turn (send
        buffer on decode, recv buffer on prefill)
    """
    info = request_id.split("_")

    if len(info) != 2:
        return info[0], "", ""

    uuid, addr_info = info
    info = addr_info.split(":")

    if len(info) != 2:
        logger.warning("unexpected request_id format: %s", request_id)
        return uuid, "", ""

    remote_ip, port = info
    return uuid, remote_ip, port


class NeuronConnector(KVConnectorBase):

    def __init__(self, rank, local_rank, vllm_config):
        self.zmq_context = zmq.Context()
        self.config = vllm_config.kv_transfer_config

        self.connection_dict = {}
        self.static_buffer = None

        self.role = "prefill" if self.config.is_kv_producer else "decode"

        # attributes for dynamic xPyD
        self.api_server_port = os.environ.get("API_SERVER_PORT", "8000")
        self.local_ip = "127.0.0.1"
        self.kv_caches = None

    def setup(self):
        # TODO: extend to static xPyD if neccessay
        self.neuron_send_ip = os.environ.get("NEURON_SEND_IP", None)
        self.neuron_recv_ip = os.environ.get("NEURON_RECV_IP", None)

        if self.neuron_recv_ip is None \
            or self.neuron_recv_ip is None \
            or self.config.kv_port is None \
            or self.config.etcd:
            logger.info("Get invalid config for static 1P1D setup, " \
                "will fallback to dynamic xPyD mode")
            self.init_etcd()
            return

        if self.config.is_kv_producer:
            self.static_buffer = NeuronBuffer(self.zmq_context,
                                              self.neuron_recv_ip,
                                              self.neuron_send_ip,
                                              self.config.kv_port,
                                              self.config.kv_map_path,
                                              send=True)
        else:
            self.static_buffer = NeuronBuffer(self.zmq_context,
                                              self.neuron_send_ip,
                                              self.neuron_send_ip,
                                              self.config.kv_port,
                                              self.config.kv_map_path,
                                              send=False)

    def _keep_alive_ectd(self):
        import etcd3
        etcd_ip, etcd_port = self.config.etcd.split(":")
        etcd_client = etcd3.client(host=etcd_ip, port=etcd_port)
        lease = create_lease_with_retry(etcd_client, ttl=60, max_retries=3)

        self.local_ip = get_local_ip()

        logger.info("Get local ip %s", self.local_ip)

        logger.info("Setting up ectd...")
        while True:
            try:
                lease.refresh()

                # TODO: report connections
                # connections = []
                # for remote_ip, buffer in self.connections.items():
                #     connections.append((remote_ip, buffer.zmq_port))
                logger.debug("%s worker dumps %s:%s", self.role, self.local_ip,
                             self.api_server_port)
                etcd_client.put(
                    f"/workers/{self.role}/{self.local_ip}/{self.api_server_port}",
                    json.dumps({"connections": []}), lease)
                time.sleep(3)
            except Exception as e:
                logger.error("Error in keep_alive_etcd: %s", e)
                # Recreate lease if needed
                lease = create_lease_with_retry(etcd_client,
                                                ttl=60,
                                                max_retries=3)

    def init_etcd(self):
        assert self.config.etcd, f"invalid etcd server addr: {self.config.etcd}"
        threading.Thread(target=self._keep_alive_ectd, daemon=True).start()

    def close(self):
        try:
            self.zmq_context.sockets_map.clear()
            self.zmq_context.term()
        except Exception as e:
            print(f"Error closing ZMQ context: {e}")

    def maybe_setup_buffer(self, remote_ip, remote_api_server_port):
        if self.static_buffer:
            return self.static_buffer

        key = (remote_ip, remote_api_server_port)
        if key in self.connection_dict:
            return self.connection_dict[key]

        # TODO: make it configurable
        # set zmq server port as API server port + 1
        if self.config.is_kv_producer:
            remote_zmq_port = str(int(self.api_server_port) + 1)
        else:
            remote_zmq_port = str(int(remote_api_server_port) + 1)

        buffer = NeuronBuffer(
            self.zmq_context,
            remote_ip,
            self.local_ip if self.config.is_kv_producer else remote_ip,
            remote_zmq_port,
            self.config.kv_map_path,
            send=self.config.is_kv_producer)
        buffer.register_kv_caches(self.kv_caches)
        self.connection_dict[key] = buffer

        return buffer

    def get_buffer(self, remote_ip, port):
        if self.static_buffer:
            return self.static_buffer

        return self.connection_dict[(remote_ip, port)]

    def register_kv_caches(self, kv_caches):
        self.kv_caches = kv_caches
        if self.static_buffer:
            self.static_buffer.register_kv_caches(kv_caches)

    def async_send_kv_caches(self, request_id, block_ids, output_token):
        logger.debug("async_send_kv_caches on %s", request_id)
        uid, remote_ip, remote_port = parse_request_id(request_id)
        buffer = self.maybe_setup_buffer(remote_ip, remote_port)
        buffer.async_send_kv_caches(uid, block_ids, output_token)

    def async_recv_kv_caches(self, request_id, block_ids):
        logger.debug("async_recv_kv_caches on %s", request_id)
        uid, remote_ip, remote_port = parse_request_id(request_id)
        buffer = self.maybe_setup_buffer(remote_ip, remote_port)
        buffer.async_recv_kv_caches(uid, block_ids)

    def check_transfer_done(self, request_id, remove=False):
        uid, remote_ip, remote_port = parse_request_id(request_id)
        buffer = self.get_buffer(remote_ip, remote_port)
        return buffer.check_transfer_done(uid, remove=remove)

    def get_output_token(self, request_id):
        uid, remote_ip, remote_port = parse_request_id(request_id)
        buffer = self.get_buffer(remote_ip, remote_port)
        return buffer.get_output_token(uid)

    # ===================== API for v0 compatibility ==================

    def send_kv_caches_and_hidden_states(
        self,
        model_executable: torch.nn.Module,
        model_input: "ModelInputForGPUWithSamplingMetadata",
        kv_caches: List[torch.Tensor],
        hidden_or_intermediate_states: Union[torch.Tensor,
                                             IntermediateTensors],
    ) -> None:

        for i in range(len(model_input.request_ids)):
            request_id = model_input.request_ids[i]
            block_ids = model_input.input_block_ids[i]
            if len(block_ids.shape) == 0:
                block_ids = block_ids.unsqueeze(0)
            block_ids = block_ids.tolist()
            output_token = hidden_or_intermediate_states[i]

            self.async_send_kv_caches(request_id, block_ids, output_token)

    def recv_kv_caches_and_hidden_states(
        self, model_executable: torch.nn.Module,
        model_input: "ModelInputForGPUWithSamplingMetadata",
        kv_caches: List[torch.Tensor]
    ) -> Tuple[Union[torch.Tensor, IntermediateTensors], bool,
               "ModelInputForGPUWithSamplingMetadata"]:

        output_tokens = []
        for request_id in model_input.request_ids:
            output_token = self.get_output_token(request_id).unsqueeze(0)
            assert self.check_transfer_done(request_id, remove=True)
            output_tokens.append(output_token)
        output_tokens = torch.cat(output_tokens, dim=0)

        return output_tokens, True, model_input
